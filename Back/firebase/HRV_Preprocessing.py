import matplotlib
matplotlib.use('Agg')
import neurokit2 as nk
import numpy as np
import pandas as pd
from datetime import datetime
from apscheduler.schedulers.background import BackgroundScheduler
from pyhrv.frequency_domain import welch_psd
from firebase_admin import db
import time
import asyncio
from config import initialize_firebase  # Import from config if needed, or rely on main init

# CONFIG
WINDOW_SIZE = 600       # 10Hz * 60s = 600 points (1 Minute Window)
COLLECTION_RATE = 10    # Raw data comes in at 10Hz
PROCESSING_RATE = 100   # Upsample to 100Hz for NeuroKit processing

# Scaling Bounds (Estimated from sample data)
SCALING_BOUNDS = {
    "LF_HF_ratio": (0, 20),
    "LF_abs": (0, 5000000),
    "HF_abs": (0, 5000000),
    "Total_Power": (0, 10000000)
}

raw_ppg_buffer = []
last_ppg_val = None  # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≥
scheduler = BackgroundScheduler()

# ==========================================
# 2. ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏î‡∏∂‡∏á‡πÅ‡∏•‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì (Core Functions)
# ==========================================
def get_ppg_from_firebase():
    """
    ‡∏î‡∏∂‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• PPG ‡∏à‡∏≤‡∏Å Firebase Path ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö EDA
    """
    try:
        # ‡πÉ‡∏ä‡πâ Path ‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö EDA ‡∏ó‡∏µ‡πà‡πÅ‡∏Å‡πâ‡πÑ‡∏Ç‡πÑ‡∏õ‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î
        ref = db.reference("/Device/Inpatient/MD-V5-0000804/1s")
        input_data = ref.get()

        if not input_data:
            return None
        else:
            # ‡∏î‡∏∂‡∏á‡∏Ñ‡πà‡∏≤ PPG (‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ä‡∏∑‡πà‡∏≠ key ‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô PPG ‡∏´‡∏£‡∏∑‡∏≠ PG)
            # ‡πÉ‡∏ô‡∏£‡∏π‡∏õ EDA ‡∏°‡∏µ key "PPG" ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏ô‡πà‡∏≤‡∏à‡∏∞‡πÉ‡∏ä‡πâ "PPG" ‡∏Ñ‡∏£‡∏±‡∏ö
            return float(input_data.get("PPG", 0))

    except Exception as e:
        print(f"Fetch Error: {e}")
        return None

def normalize_value(val, min_v, max_v):
    """Simple MinMax Scaler with clamping 0-1"""
    if val < min_v: return 0.0
    if val > max_v: return 1.0
    return (val - min_v) / (max_v - min_v)

def store_hrv_to_firebase(features):
    try:
        ref = db.reference("/Preprocessing/HRV")
        ref.set(features)
        print("-" * 50)
        print(f"‚úÖ UPDATED FIREBASE at {features['Timestamp']}")
        print(f"   LF/HF (Norm): {features['LF_HF_ratio_Normalized']:.4f} | Total Power (Norm): {features['Total_Power_Normalized']:.4f}")
        print("-" * 50)
    except Exception as e:
        print(f"Error saving: {e}")


def process_hrv_window(ppg_data_list):
    try:
        ppg_signal = np.array(ppg_data_list, dtype=float)

        # 0. Resample: 10Hz -> 100Hz
        # NeuroKit needs higher sampling rate for effective filtering
        ppg_resampled = nk.signal_resample(
            ppg_signal, 
            sampling_rate=COLLECTION_RATE, 
            desired_sampling_rate=PROCESSING_RATE
        )

        # 1. Clean
        ppg_cleaned = nk.ppg_clean(ppg_resampled, sampling_rate=PROCESSING_RATE)

        # 2. Peaks
        signals, info = nk.ppg_peaks(ppg_cleaned, sampling_rate=PROCESSING_RATE)
        peaks = info['PPG_Peaks']

        if len(peaks) == 0:
            print("‚ö†Ô∏è Not enough peaks detected.")
            return None

        # 3. NNI & Welch
        nni = np.diff(peaks) * 1000 / PROCESSING_RATE

        # ‡∏ï‡πâ‡∏≠‡∏á‡∏°‡∏µ‡∏ä‡πà‡∏ß‡∏á NNI ‡∏°‡∏≤‡∏Å‡∏û‡∏≠‡∏ñ‡∏∂‡∏á‡∏à‡∏∞‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì PSD ‡πÑ‡∏î‡πâ
        if len(nni) == 0:
            print("‚ö†Ô∏è NNI too short for Frequency analysis.")
            return None

        freq_results = welch_psd(nni=nni, show=False)
        freq_dict = freq_results.as_dict()
        
        # Raw Values
        lf_hf_raw = float(freq_dict['fft_ratio'])
        lf_n_raw = float(freq_dict['fft_norm'][0])
        hf_n_raw = float(freq_dict['fft_norm'][1])
        lf_abs_raw = float(freq_dict['fft_abs'][1])
        hf_abs_raw = float(freq_dict['fft_abs'][2])
        total_power_raw = float(freq_dict['fft_total'])

        return {
            "Timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            
            # --- Normalized Values (0-1) ---
            "LF_HF_ratio_Normalized": normalize_value(lf_hf_raw, *SCALING_BOUNDS["LF_HF_ratio"]),
            "LF_n_Normalized": lf_n_raw / 100.0, # LF_n is 0-100
            "HF_n_Normalized": hf_n_raw / 100.0, # HF_n is 0-100
            "LF_abs_Normalized": normalize_value(lf_abs_raw, *SCALING_BOUNDS["LF_abs"]),
            "HF_abs_Normalized": normalize_value(hf_abs_raw, *SCALING_BOUNDS["HF_abs"]),
            "Total_Power_Normalized": normalize_value(total_power_raw, *SCALING_BOUNDS["Total_Power"]),
            
            # --- Raw Values (Keep for reference) ---
            "LF_HF_ratio_Raw": lf_hf_raw,
            "LF_n_Raw": lf_n_raw,
            "HF_n_Raw": hf_n_raw,
            "LF_abs_Raw": lf_abs_raw,
            "HF_abs_Raw": hf_abs_raw,
            "Total_Power_Raw": total_power_raw
        }
    except Exception as e:
        print(f"Calc Error: {e}")
        return None


def collect_and_process_ppg():
    global raw_ppg_buffer

    # 1. ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤
    new_val = get_ppg_from_firebase()

    if new_val is not None:
        raw_ppg_buffer.append(new_val)

        # Debug print: ‡πÇ‡∏ä‡∏ß‡πå‡∏Ñ‡πà‡∏≤ buffer size ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏î‡∏π‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏∑‡∏ö‡∏´‡∏ô‡πâ‡∏≤
        if len(raw_ppg_buffer) % 10 == 0:
            print(f"DEBUG: PPG Buffered {len(raw_ppg_buffer)}/{WINDOW_SIZE} | Data: {new_val}")

    # 2. Sliding Window (‡∏ñ‡πâ‡∏≤ buffer ‡πÄ‡∏ï‡πá‡∏° ‡πÉ‡∏´‡πâ‡πÄ‡∏≠‡∏≤‡∏ï‡∏±‡∏ß‡πÄ‡∏Å‡πà‡∏≤‡∏≠‡∏≠‡∏Å)
    if len(raw_ppg_buffer) > WINDOW_SIZE:
        raw_ppg_buffer.pop(0)

    # 3. Process ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏ï‡πá‡∏°
    if len(raw_ppg_buffer) == WINDOW_SIZE:
        # ‡∏≠‡∏≤‡∏à‡∏à‡∏∞ process ‡∏ó‡∏∏‡∏Å‡πÜ  interval ‡∏´‡∏£‡∏∑‡∏≠‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ ‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ‡∏≠‡∏≤‡∏à‡∏à‡∏∞ process ‡∏ó‡∏∏‡∏Å‡πÜ X ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        # ‡πÅ‡∏ï‡πà‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏ó‡∏≥‡∏ï‡∏≤‡∏° logic ‡πÄ‡∏î‡∏¥‡∏°‡∏Ñ‡∏∑‡∏≠‡πÄ‡∏ï‡πá‡∏°‡πÅ‡∏•‡πâ‡∏ß process ‡πÄ‡∏•‡∏¢
        features = process_hrv_window(raw_ppg_buffer)
        if features:
            store_hrv_to_firebase(features)
            # Reset buffer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà ‡∏´‡∏£‡∏∑‡∏≠ ‡∏à‡∏∞‡∏ó‡∏≥ sliding window ‡∏à‡∏£‡∏¥‡∏á‡πÜ (‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏Å‡πà‡∏≤‡πÑ‡∏ß‡πâ) ‡∏Å‡πá‡πÑ‡∏î‡πâ
            # ‡πÅ‡∏ï‡πà‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏á‡πà‡∏≤‡∏¢‡πÅ‡∏•‡∏∞‡πÄ‡∏´‡∏°‡∏∑‡∏≠‡∏ô EDA ‡πÄ‡∏£‡∏≤ Reset ‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÑ‡∏´‡∏°? 
            # ‡πÅ‡∏ï‡πà HRV ‡∏õ‡∏Å‡∏ï‡∏¥‡∏ï‡πâ‡∏≠‡∏á‡πÉ‡∏ä‡πâ‡∏ä‡πà‡∏ß‡∏á‡πÄ‡∏ß‡∏•‡∏≤‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á ‡∏ñ‡πâ‡∏≤ Reset ‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏Ç‡∏≤‡∏î‡∏ï‡∏≠‡∏ô
            # ‡πÉ‡∏ô‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πâ‡∏Ç‡∏≠‡πÉ‡∏ä‡πâ‡πÅ‡∏ö‡∏ö Sliding: pop ‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å‡∏≠‡∏≠‡∏Å‡πÑ‡∏õ‡πÅ‡∏•‡πâ‡∏ß (‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡∏ö‡∏ô) ‡∏î‡∏±‡∏á‡∏ô‡∏±‡πâ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏∞ shift ‡∏ó‡∏µ‡∏•‡∏∞ 1 ‡∏à‡∏∏‡∏î
            # ‡πÅ‡∏ï‡πà process ‡∏ó‡∏∏‡∏Å 1 ‡∏à‡∏∏‡∏î‡∏à‡∏∞‡∏´‡∏ô‡∏±‡∏Å‡πÑ‡∏õ ‡πÉ‡∏´‡πâ process ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡∏Ñ‡∏£‡∏ö‡∏£‡∏≠‡∏ö‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤
            pass


# ‡∏õ‡∏£‡∏±‡∏ö logic: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏°‡πà‡πÉ‡∏´‡πâ‡∏´‡∏ô‡∏±‡∏Å‡πÄ‡∏Å‡∏¥‡∏ô‡πÑ‡∏õ ‡πÄ‡∏£‡∏≤‡∏à‡∏∞ process ‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡∏Ñ‡∏£‡∏ö set
def collect_and_process_ppg_batch():
    global raw_ppg_buffer, last_ppg_val
    new_val = get_ppg_from_firebase()
    
    # Simple Duplicate Filter: ‡πÄ‡∏≠‡∏≤‡∏≠‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏ã‡πâ‡∏≥‡πÑ‡∏î‡πâ
    if new_val is not None:
        # if new_val != last_ppg_val:  <-- Comment Out Duplicate Check
        raw_ppg_buffer.append(new_val)
        last_ppg_val = new_val
        
        # Debug: ‡πÅ‡∏™‡∏î‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Ç‡πâ‡∏≤
        print(f"DEBUG: Data Count {len(raw_ppg_buffer)}/{WINDOW_SIZE} | Value: {new_val}")
        
    if len(raw_ppg_buffer) >= WINDOW_SIZE:
        print("üîÑ Processing HRV Batch...")
        features = process_hrv_window(raw_ppg_buffer)
        if features:
            store_hrv_to_firebase(features)
        
        # Reset buffer ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏£‡∏≠‡∏ä‡∏∏‡∏î‡πÉ‡∏´‡∏°‡πà (Overlap ‡∏ô‡∏¥‡∏î‡∏´‡∏ô‡πà‡∏≠‡∏¢‡∏≠‡∏≤‡∏à‡∏à‡∏∞‡∏î‡∏µ‡∏Å‡∏ß‡πà‡∏≤‡πÅ‡∏ï‡πà‡πÄ‡∏≠‡∏≤‡πÅ‡∏ö‡∏ö Simple ‡∏Å‡πà‡∏≠‡∏ô)
        raw_ppg_buffer = []

# ==========================================
# 3. Scheduler & Async Start
# ==========================================
def schedule_preprocessing_interval():
    if not scheduler.get_jobs():
        # PPG ‡∏°‡∏≤‡∏ñ‡∏µ‡πà‡∏Å‡∏ß‡πà‡∏≤ EDA ‡∏°‡∏±‡∏Å‡∏à‡∏∞‡∏°‡∏≤ 10-100Hz 
        # ‡∏™‡∏°‡∏°‡∏ï‡∏¥ Firebase ‡πÄ‡∏Å‡πá‡∏ö 1 ‡∏Ñ‡πà‡∏≤‡∏•‡πà‡∏≤‡∏™‡∏∏‡∏î‡πÄ‡∏™‡∏°‡∏≠ ‡πÄ‡∏£‡∏≤‡∏ï‡πâ‡∏≠‡∏á‡∏î‡∏∂‡∏á‡πÉ‡∏´‡πâ‡∏ó‡∏±‡∏ô
        scheduler.add_job(collect_and_process_ppg_batch, trigger='interval', seconds=0.1, max_instances=10)
        scheduler.start()
        print("‚è∞ HRV Scheduler started.")

async def start_schedule_preprocessing_hrv():
    try:
        schedule_preprocessing_interval()
        return {"message": "Started scheduling preprocessing HRV"}
    except Exception as e:
        return {"error": str(e)}
